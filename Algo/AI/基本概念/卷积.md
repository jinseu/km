
## 简介

卷积首先是一个数学概念，在泛函分析中，卷积（convolution）是透过两个函数 f 和 g 生成第三个函数的一种数学算子，表征函数 f 与经过翻转和平移的 g 的乘积函数所围成的曲边梯形的面积。如果将参加卷积的一个函数看作区间的指示函数，卷积还可以被看作是“移动平均”的推广。

卷积是数学分析中一种重要的运算。设：f(x), g(x) 是两个可积函数，

[!卷积](./img/convolution.svg)

这个积分就定义了一个新函数h(x)，称为函数f(x)，g(x)的卷积。对于卷积的理解，可以采用如下方式

- 已知两函数f(t)和g(t)。
- 首先将两个函数都用x来表示，从而得到f(x)和g(x)。将函数g(x)向左移动t个单位，得到函数g(x+t)的图像。将g(x+t)翻转至纵轴另一侧，得到g(t-x)的图像。
- 由于t非常数（实际上是时间变量），当时间变量（以下简称“时移”）取不同值时，g(t-x)能沿着x轴“滑动”。
- 让x从-∞滑动到+∞。两函数交会时，计算交会范围中两函数乘积的积分值。换句话说，我们是在计算一个滑动的的加权总和(weighted-sum)。也就是使用g(t-x)当做加权函数，来对f(x)取加权值。


在深度学习中，通过卷积实现前后两层神经元的稀疏链接，由于卷积核一般较小，相对而言权重数目也比较少，可以有效减少训练参数的数目，加快模型的训练和收敛速度。

## 例子

下面的例子中通过卷积实现一个sedol滤波器，来得到一幅图片边缘。

```Python
#!/usr/bin/env python
# coding: utf-8
import torch
import numpy as np
from torch import nn
from PIL import Image
from torch.autograd import Variable
import torch.nn.functional as F
import cv2
im = cv2.imread('./cat.jpeg', flags=1)
im = np.transpose(im, (2, 0, 1))
im = im[np.newaxis, :]
im = torch.Tensor(im)
conv_op = nn.Conv2d(3, 3, kernel_size=3, padding=1, bias=False)
sobel_kernel = np.array([[-1, -1, -1], [-1, 8, -1], [-1, -1, -1]], dtype='float32') / 3
sobel_kernel = sobel_kernel.reshape((1, 1, 3, 3))
sobel_kernel = np.repeat(sobel_kernel, 3, axis=1)
sobel_kernel = np.repeat(sobel_kernel, 3, axis=0)
conv_op.weight.data = torch.from_numpy(sobel_kernel)
edge_detect = conv_op(im)
edge_detect = edge_detect.squeeze().detach().numpy()
edge_detect = np.transpose(edge_detect, (1, 2, 0))
cv2.imwrite('edge-cat.jpeg', edge_detect)
```