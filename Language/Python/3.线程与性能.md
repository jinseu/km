## 线程与性能

### GIL

GIL 存在的目的是为了保护python中内存的访问。因为python采用了引用计数的方式，所以当多个线程共享一个变量时，如果没有GIL，name在操作refcnt的过程中，就可能出现并发错误。而GIL的存在则保证了refcnt操作的正确性，同时也限制了，在同一时间，只有一个python线程可以访问python提供的API，导致一个python进程无论创建多少个线程也不能利用多核的计算能力。当然针对这个问题，目前的解决办法是引入多个python进程，彼此间用IPC(InterProcess Communication)的形式通信，从而充分利用多核的计算能力。

python 线程的调度是由python解释器决定的，在每执行N个指令后，解释器就会尝试强制挂起当前线程，在就绪的线程池中选择一个来执行，N的值可以通过以下方式获得。

```
import sys
sys.getcheckinterval()
```

至于具体选择哪一个，python则是完全交由操作系统决定。这也就意味着，python中的线程对应着操作系统中原生的线程。只不过限制了这些线程的调度与执行，只有获得GIL的线程才可以执行。

Python在启动时，并不支持多线程，而是在调用`PyEval_InitThreads`后才会激活多线程，当然系统会保证该方法仅执行一次。Python 线程通过调用`PyThread_acquire_lock`来获取GIL，`PyThread_free_lock`来释放GIL。

`~PyThread_acquire_lock`的实现是平台相关的，例如在linux平台上，对应的lock实际上就是`sem_t *thelock = (sem_t *)lock;`然后通过sem_wait和sem_post完成GIL的获取和释放。

事实上，GIL的获取是在调用Python 解释器代码之前，这也就意味着多个线程是有可能同时运行python各自的代码，以及同一个进程内多个线程的CPU占用之和大于100%的原因。

一个线程失去GIL并没有被挂起，而是继续被操作系统唤醒，此时，该线程会去继续申请GIL，此时才会被真正挂起，即从失去GIL到挂起，多个线程是可以并行的，此时checkinterval越小，多个线程就会不断的交替释放锁，获取锁，从而导致多个线程的CPU占用之和越接近n*100%，注意由于`goto fast_next_opcode` 的存在，每次切换时并不能保证真的执行了checkinterval条指令，比如`if，while`等语句的存在就会导致每次切换时执行的指令数大于checkinterval。

while CPython does use operating system threads (in theory allowing multiple threads to execute within the interpreter simultaneously), the interpreter also forces the GIL to be acquired by a thread before it can access the interpreter and stack and can modify Python objects in memory all willy-nilly.

具体代码如下所示，_Py_Ticker为内部计数器

```
if (--_Py_Ticker < 0) {
            if (*next_instr == SETUP_FINALLY) {
                /* Make the last opcode before
                   a try: finally: block uninterruptible. */
                goto fast_next_opcode;
            }
            _Py_Ticker = _Py_CheckInterval;
            tstate->tick_counter++;
#ifdef WITH_TSC
            ticked = 1;
#endif
            if (pendingcalls_to_do) {
                if (Py_MakePendingCalls() < 0) {
                    why = WHY_EXCEPTION;
                    goto on_error;
                }
                if (pendingcalls_to_do)
                    /* MakePendingCalls() didn't succeed.
                       Force early re-execution of this
                       "periodic" code, possibly after
                       a thread switch */
                    _Py_Ticker = 0;
            }
#ifdef WITH_THREAD
            if (interpreter_lock) {
                /* Give another thread a chance */

                if (PyThreadState_Swap(NULL) != tstate)
                    Py_FatalError("ceval: tstate mix-up");
                PyThread_release_lock(interpreter_lock);

                /* Other threads may run now */

                PyThread_acquire_lock(interpreter_lock, 1);

                if (PyThreadState_Swap(tstate) != NULL)
                    Py_FatalError("ceval: orphan tstate");

                /* Check for thread interrupts */

                if (tstate->async_exc != NULL) {
                    x = tstate->async_exc;
                    tstate->async_exc = NULL;
                    PyErr_SetNone(x);
                    Py_DECREF(x);
                    why = WHY_EXCEPTION;
                    goto on_error;
                }
            }
#endif
        }
        
```

### 线程

关于线程的内容在GIL中，也讲了很多，剩余的部分中，关键是`threading.Lock()`。GIL可以看做是对解释器层面的资源访问的保护，线程锁则是提供了对用户程序中数据访问的保护机制。

线程锁释放和获取时，使用的方法和GIL是相同的，都是`PyThread_acquire_lock`。但是为了避免死锁，线程在获取线程锁之前，会先调用`Py_BEGIN_ALLOW_THREADS`释放GIL，允许其他线程运行，然后在获取线程锁之后，再次调用`Py_END_ALLOW_THREADS`获取GIL，继续执行。

事实上，python会在可能阻塞的系统调用之前，`Py_BEGIN_ALLOW_THREADS`释放GIL，系统调用完毕后，`Py_END_ALLOW_THREADS`重新获取GIL。


python threading模块提供了 Lock, RLock，Condition，Semaphore以及Event，用来做线程间的同步和并发控制。以上五个对象的底层实现中都用到了和GIL相似的逻辑。

### cProfile

### line_profiler

### memory_profiler

### insppecting heap

guppy

dowser




 
